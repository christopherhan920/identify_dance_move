{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad32719",
   "metadata": {},
   "source": [
    "# Identify Dance Move: Transfer Learning\n",
    "\n",
    "## Part 1: Load Videos, Preprocess, and Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fb6bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec002c6",
   "metadata": {},
   "source": [
    "Following the tutorial from here: https://keras.io/examples/vision/video_classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c91f7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25efef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c8a37f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_feature_extractor():\n",
    "    feature_extractor = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2772f08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stick and Roll', 'Brooklyn', 'Charleston', 'Monastery']\n"
     ]
    }
   ],
   "source": [
    "moves = os.listdir('data')\n",
    "moves.remove('.DS_Store')\n",
    "moves.remove('all_combined')\n",
    "print(moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9db63685",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stick and Roll', 'Brooklyn', 'Charleston', 'Monastery']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/idm/lib/python3.8/site-packages/numpy/core/numeric.py:2463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    }
   ],
   "source": [
    "label_processor = keras.layers.StringLookup(\n",
    "    num_oov_indices=0, vocabulary=moves\n",
    ")\n",
    "print(label_processor.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a47b9f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 video_name             tag\n",
      "0                              IMG_4742.MOV  Stick and Roll\n",
      "1  2B780CEE-3D09-4820-BEFD-CFDFF074F444.mov  Stick and Roll\n",
      "2                              IMG_4753.MOV  Stick and Roll\n",
      "3  2B93BBED-F225-4523-9DC6-31ABB7347F2F.mov  Stick and Roll\n",
      "4  24FD3C61-03D2-4BAA-9F27-BE0A1743C71A.mov  Stick and Roll\n"
     ]
    }
   ],
   "source": [
    "# iterate through each folder and file and add the file name and label to a table\n",
    "\n",
    "filenames = []\n",
    "labels = []\n",
    "\n",
    "for move in moves:\n",
    "    filenames = filenames + os.listdir('data/{}'.format(move))\n",
    "    labels = labels + [move] * len(os.listdir('data/{}'.format(move)))\n",
    "\n",
    "df = pd.DataFrame({'video_name': filenames, 'tag': labels})\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63c85bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size = 0.2, random_state = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18554b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>IMG_9221.mov</td>\n",
       "      <td>Brooklyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>IMG_4754.MOV</td>\n",
       "      <td>Monastery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5D8BB37D-643F-4976-9104-BBDD2E7B1CAC.mov</td>\n",
       "      <td>Monastery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1D94BB45-0578-489C-A52F-418B6F1279F7.mov</td>\n",
       "      <td>Brooklyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>IMG_4702.MOV</td>\n",
       "      <td>Charleston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IMG_4749.MOV</td>\n",
       "      <td>Stick and Roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24FD3C61-03D2-4BAA-9F27-BE0A1743C71A.mov</td>\n",
       "      <td>Stick and Roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>IMG_4687.MOV</td>\n",
       "      <td>Monastery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>698334CC-5E67-4CE3-8C7F-A1390D0488B9.mov</td>\n",
       "      <td>Charleston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2B93BBED-F225-4523-9DC6-31ABB7347F2F.mov</td>\n",
       "      <td>Stick and Roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>IMG_4698.MOV</td>\n",
       "      <td>Charleston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG_4742.MOV</td>\n",
       "      <td>Stick and Roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8EFD7A3A-DF83-4146-99C8-2233A1B50554.mov</td>\n",
       "      <td>Stick and Roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>IMG_4689.MOV</td>\n",
       "      <td>Monastery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>C875154C-4887-4A91-812B-3E314A7E080E.mov</td>\n",
       "      <td>Charleston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>IMG_4748.MOV</td>\n",
       "      <td>Monastery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RPReplay_Final1658454035.mp4</td>\n",
       "      <td>Brooklyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IMG_9223.mov</td>\n",
       "      <td>Stick and Roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2116E609-5176-49C8-9F92-0B97EF341606.mov</td>\n",
       "      <td>Stick and Roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IMG_4738.MOV</td>\n",
       "      <td>Stick and Roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IMG_4690.MOV</td>\n",
       "      <td>Stick and Roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0DBBC49D-DD09-4D93-8B2E-5A8E2D9C87AD.mov</td>\n",
       "      <td>Brooklyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2B780CEE-3D09-4820-BEFD-CFDFF074F444.mov</td>\n",
       "      <td>Stick and Roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4C08206C-C5B8-454C-AAF3-3CD0A06FEA45.mov</td>\n",
       "      <td>Monastery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>IMG_4739.MOV</td>\n",
       "      <td>Monastery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2C30C94B-63BA-47A1-88C5-D2228609EA98.mov</td>\n",
       "      <td>Brooklyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IMG_4699.MOV</td>\n",
       "      <td>Stick and Roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>IMG_9224.mov</td>\n",
       "      <td>Monastery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>IMG_4760.MOV</td>\n",
       "      <td>Monastery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>IMG_4691.MOV</td>\n",
       "      <td>Monastery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>IMG_4695.MOV</td>\n",
       "      <td>Charleston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>IMG_9222.mov</td>\n",
       "      <td>Charleston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>IMG_4743.MOV</td>\n",
       "      <td>Monastery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>F795CDC5-9FD9-47BA-BA5C-560641AB9E6C.mov</td>\n",
       "      <td>Monastery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>IMG_4744.MOV</td>\n",
       "      <td>Charleston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>IMG_4694.MOV</td>\n",
       "      <td>Charleston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>IMG_4740.MOV</td>\n",
       "      <td>Charleston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>AAE51822-E3FE-43D0-ABC1-7EB39DFA042B.mov</td>\n",
       "      <td>Charleston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RPReplay_Final1658454103.mp4</td>\n",
       "      <td>Stick and Roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>RPReplay_Final1658454066.mp4</td>\n",
       "      <td>Monastery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>BDC1709F-3A46-423A-B642-3628BCC603EA.mov</td>\n",
       "      <td>Monastery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>IMG_4704.MOV</td>\n",
       "      <td>Monastery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>IMG_4747.MOV</td>\n",
       "      <td>Charleston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>IMG_4761.MOV</td>\n",
       "      <td>Charleston</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  video_name             tag\n",
       "20                              IMG_9221.mov        Brooklyn\n",
       "39                              IMG_4754.MOV       Monastery\n",
       "51  5D8BB37D-643F-4976-9104-BBDD2E7B1CAC.mov       Monastery\n",
       "21  1D94BB45-0578-489C-A52F-418B6F1279F7.mov        Brooklyn\n",
       "31                              IMG_4702.MOV      Charleston\n",
       "15                              IMG_4749.MOV  Stick and Roll\n",
       "4   24FD3C61-03D2-4BAA-9F27-BE0A1743C71A.mov  Stick and Roll\n",
       "43                              IMG_4687.MOV       Monastery\n",
       "32  698334CC-5E67-4CE3-8C7F-A1390D0488B9.mov      Charleston\n",
       "3   2B93BBED-F225-4523-9DC6-31ABB7347F2F.mov  Stick and Roll\n",
       "33                              IMG_4698.MOV      Charleston\n",
       "0                               IMG_4742.MOV  Stick and Roll\n",
       "10  8EFD7A3A-DF83-4146-99C8-2233A1B50554.mov  Stick and Roll\n",
       "45                              IMG_4689.MOV       Monastery\n",
       "38  C875154C-4887-4A91-812B-3E314A7E080E.mov      Charleston\n",
       "53                              IMG_4748.MOV       Monastery\n",
       "18              RPReplay_Final1658454035.mp4        Brooklyn\n",
       "12                              IMG_9223.mov  Stick and Roll\n",
       "6   2116E609-5176-49C8-9F92-0B97EF341606.mov  Stick and Roll\n",
       "11                              IMG_4738.MOV  Stick and Roll\n",
       "7                               IMG_4690.MOV  Stick and Roll\n",
       "19  0DBBC49D-DD09-4D93-8B2E-5A8E2D9C87AD.mov        Brooklyn\n",
       "1   2B780CEE-3D09-4820-BEFD-CFDFF074F444.mov  Stick and Roll\n",
       "42  4C08206C-C5B8-454C-AAF3-3CD0A06FEA45.mov       Monastery\n",
       "49                              IMG_4739.MOV       Monastery\n",
       "17  2C30C94B-63BA-47A1-88C5-D2228609EA98.mov        Brooklyn\n",
       "13                              IMG_4699.MOV  Stick and Roll\n",
       "47                              IMG_9224.mov       Monastery\n",
       "52                              IMG_4760.MOV       Monastery\n",
       "44                              IMG_4691.MOV       Monastery\n",
       "29                              IMG_4695.MOV      Charleston\n",
       "35                              IMG_9222.mov      Charleston\n",
       "40                              IMG_4743.MOV       Monastery\n",
       "41  F795CDC5-9FD9-47BA-BA5C-560641AB9E6C.mov       Monastery\n",
       "27                              IMG_4744.MOV      Charleston\n",
       "28                              IMG_4694.MOV      Charleston\n",
       "23                              IMG_4740.MOV      Charleston\n",
       "37  AAE51822-E3FE-43D0-ABC1-7EB39DFA042B.mov      Charleston\n",
       "14              RPReplay_Final1658454103.mp4  Stick and Roll\n",
       "55              RPReplay_Final1658454066.mp4       Monastery\n",
       "50  BDC1709F-3A46-423A-B642-3628BCC603EA.mov       Monastery\n",
       "48                              IMG_4704.MOV       Monastery\n",
       "25                              IMG_4747.MOV      Charleston\n",
       "36                              IMG_4761.MOV      Charleston"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6338304",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on video 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 20:33:56.633849: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on video 1\n",
      "Working on video 2\n",
      "Working on video 3\n",
      "Working on video 4\n",
      "Working on video 5\n",
      "Working on video 6\n",
      "Working on video 7\n",
      "Working on video 8\n",
      "Working on video 9\n",
      "Working on video 10\n",
      "Working on video 11\n",
      "Working on video 12\n",
      "Working on video 13\n",
      "Working on video 14\n",
      "Working on video 15\n",
      "Working on video 16\n",
      "Working on video 17\n",
      "Working on video 18\n",
      "Working on video 19\n",
      "Working on video 20\n",
      "Working on video 21\n",
      "Working on video 22\n",
      "Working on video 23\n",
      "Working on video 24\n",
      "Working on video 25\n",
      "Working on video 26\n",
      "Working on video 27\n",
      "Working on video 28\n",
      "Working on video 29\n",
      "Working on video 30\n",
      "Working on video 31\n",
      "Working on video 32\n",
      "Working on video 33\n",
      "Working on video 34\n",
      "Working on video 35\n",
      "Working on video 36\n",
      "Working on video 37\n",
      "Working on video 38\n",
      "Working on video 39\n",
      "Working on video 40\n",
      "Working on video 41\n",
      "Working on video 42\n",
      "Working on video 43\n",
      "Working on video 0\n",
      "Working on video 1\n",
      "Working on video 2\n",
      "Working on video 3\n",
      "Working on video 4\n",
      "Working on video 5\n",
      "Working on video 6\n",
      "Working on video 7\n",
      "Working on video 8\n",
      "Working on video 9\n",
      "Working on video 10\n",
      "Working on video 11\n",
      "Frame features in train set: (44, 20, 2048)\n",
      "Frame masks in train set: (44, 20)\n"
     ]
    }
   ],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"video_name\"].values.tolist()\n",
    "    labels = df[\"tag\"].values\n",
    "    labels = label_processor(labels[..., None]).numpy()\n",
    "\n",
    "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
    "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
    "    # masked with padding or not.\n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros(\n",
    "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "    # For each video.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        print('Working on video {}'.format(idx))\n",
    "        # Gather all its frames and add a batch dimension.\n",
    "        frames = load_video(os.path.join(root_dir, path))\n",
    "        frames = frames[None, ...]\n",
    "\n",
    "        # Initialize placeholders to store the masks and features of the current video.\n",
    "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # Extract features from the frames of the current video.\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                    batch[None, j, :]\n",
    "                )\n",
    "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "\n",
    "    return (frame_features, frame_masks), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51516154",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = prepare_all_videos(train_df, \"data/all_combined\")\n",
    "test_data, test_labels = prepare_all_videos(test_df, \"data/all_combined\")\n",
    "\n",
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c86f337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_data, open('arrays/train_data', 'wb'))\n",
    "pickle.dump(train_labels, open('arrays/train_labels', 'wb'))\n",
    "pickle.dump(test_data, open('arrays/test_data', 'wb'))\n",
    "pickle.dump(test_labels, open('arrays/test_labels', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f47b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open('arrays/train_data', 'rb'))\n",
    "train_labels = pickle.load(open('arrays/train_labels', 'rb'))\n",
    "test_data = pickle.load(open('arrays/test_data', 'rb'))\n",
    "test_labels = pickle.load(open('arrays/test_labels', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409eb763",
   "metadata": {},
   "source": [
    "## Part 2: Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a3b4841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility for our sequence model.\n",
    "def get_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
    "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
    "    x = keras.layers.GRU(16, return_sequences=True)(\n",
    "        frame_features_input, mask=mask_input\n",
    "    )\n",
    "    x = keras.layers.GRU(8)(x)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
    "\n",
    "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return rnn_model\n",
    "\n",
    "\n",
    "# Utility for running experiments.\n",
    "def run_experiment():\n",
    "    filepath = \"/tmp/video_classifier\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1]],\n",
    "        train_labels,\n",
    "        validation_split=0.3,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint],\n",
    "    )\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b94f8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 11:18:33.655992: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 1.3684 - accuracy: 0.2667\n",
      "Epoch 1: val_loss improved from inf to 1.41479, saving model to /tmp/video_classifier\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.3684 - accuracy: 0.2667 - val_loss: 1.4148 - val_accuracy: 0.3571\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3332 - accuracy: 0.3000\n",
      "Epoch 2: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.3332 - accuracy: 0.3000 - val_loss: 1.5755 - val_accuracy: 0.2143\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3468 - accuracy: 0.3333\n",
      "Epoch 3: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3468 - accuracy: 0.3333 - val_loss: 1.6588 - val_accuracy: 0.3571\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3238 - accuracy: 0.3333\n",
      "Epoch 4: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3238 - accuracy: 0.3333 - val_loss: 1.7349 - val_accuracy: 0.3571\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3459 - accuracy: 0.3667\n",
      "Epoch 5: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3459 - accuracy: 0.3667 - val_loss: 1.7344 - val_accuracy: 0.3571\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2959 - accuracy: 0.3000\n",
      "Epoch 6: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2959 - accuracy: 0.3000 - val_loss: 1.7207 - val_accuracy: 0.3571\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2207 - accuracy: 0.3333\n",
      "Epoch 7: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2207 - accuracy: 0.3333 - val_loss: 1.6532 - val_accuracy: 0.2857\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1742 - accuracy: 0.3333\n",
      "Epoch 8: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1742 - accuracy: 0.3333 - val_loss: 1.7163 - val_accuracy: 0.2857\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2092 - accuracy: 0.2667\n",
      "Epoch 9: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2092 - accuracy: 0.2667 - val_loss: 1.8060 - val_accuracy: 0.2143\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2266 - accuracy: 0.2333\n",
      "Epoch 10: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2266 - accuracy: 0.2333 - val_loss: 1.8559 - val_accuracy: 0.2143\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1527 - accuracy: 0.4667\n",
      "Epoch 11: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1527 - accuracy: 0.4667 - val_loss: 1.8892 - val_accuracy: 0.1429\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1027 - accuracy: 0.4000\n",
      "Epoch 12: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1027 - accuracy: 0.4000 - val_loss: 1.9092 - val_accuracy: 0.0714\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1083 - accuracy: 0.4000\n",
      "Epoch 13: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1083 - accuracy: 0.4000 - val_loss: 1.9216 - val_accuracy: 0.0714\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1063 - accuracy: 0.4000\n",
      "Epoch 14: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1063 - accuracy: 0.4000 - val_loss: 1.9206 - val_accuracy: 0.0714\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0287 - accuracy: 0.5000\n",
      "Epoch 15: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0287 - accuracy: 0.5000 - val_loss: 1.9114 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1114 - accuracy: 0.5000\n",
      "Epoch 16: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1114 - accuracy: 0.5000 - val_loss: 1.8943 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0661 - accuracy: 0.4667\n",
      "Epoch 17: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0661 - accuracy: 0.4667 - val_loss: 1.8707 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0384 - accuracy: 0.5667\n",
      "Epoch 18: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0384 - accuracy: 0.5667 - val_loss: 1.8877 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0460 - accuracy: 0.5000\n",
      "Epoch 19: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0460 - accuracy: 0.5000 - val_loss: 1.9221 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0531 - accuracy: 0.4667\n",
      "Epoch 20: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0531 - accuracy: 0.4667 - val_loss: 1.9532 - val_accuracy: 0.0714\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0395 - accuracy: 0.5000\n",
      "Epoch 21: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0395 - accuracy: 0.5000 - val_loss: 1.9818 - val_accuracy: 0.0714\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0606 - accuracy: 0.4000\n",
      "Epoch 22: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0606 - accuracy: 0.4000 - val_loss: 1.9971 - val_accuracy: 0.0714\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0025 - accuracy: 0.5333\n",
      "Epoch 23: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0025 - accuracy: 0.5333 - val_loss: 2.0159 - val_accuracy: 0.0714\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0671 - accuracy: 0.3000\n",
      "Epoch 24: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0671 - accuracy: 0.3000 - val_loss: 2.0381 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0914 - accuracy: 0.4333\n",
      "Epoch 25: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0914 - accuracy: 0.4333 - val_loss: 2.0659 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9861 - accuracy: 0.4333\n",
      "Epoch 26: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9861 - accuracy: 0.4333 - val_loss: 2.1024 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9526 - accuracy: 0.4667\n",
      "Epoch 27: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9526 - accuracy: 0.4667 - val_loss: 2.1297 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0009 - accuracy: 0.4667\n",
      "Epoch 28: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0009 - accuracy: 0.4667 - val_loss: 2.1511 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9950 - accuracy: 0.4333\n",
      "Epoch 29: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9950 - accuracy: 0.4333 - val_loss: 2.1709 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0257 - accuracy: 0.5000\n",
      "Epoch 30: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0257 - accuracy: 0.5000 - val_loss: 2.1796 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 1.0346 - accuracy: 0.4000\n",
      "Epoch 31: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0346 - accuracy: 0.4000 - val_loss: 2.1804 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9594 - accuracy: 0.5000\n",
      "Epoch 32: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9594 - accuracy: 0.5000 - val_loss: 2.1804 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9213 - accuracy: 0.5667\n",
      "Epoch 33: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9213 - accuracy: 0.5667 - val_loss: 2.1837 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9980 - accuracy: 0.5000\n",
      "Epoch 34: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9980 - accuracy: 0.5000 - val_loss: 2.1757 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9475 - accuracy: 0.6333\n",
      "Epoch 35: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9475 - accuracy: 0.6333 - val_loss: 2.1674 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9513 - accuracy: 0.5000\n",
      "Epoch 36: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9513 - accuracy: 0.5000 - val_loss: 2.1614 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9713 - accuracy: 0.6000\n",
      "Epoch 37: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9713 - accuracy: 0.6000 - val_loss: 2.1638 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9583 - accuracy: 0.5000\n",
      "Epoch 38: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9583 - accuracy: 0.5000 - val_loss: 2.1736 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9749 - accuracy: 0.4333\n",
      "Epoch 39: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9749 - accuracy: 0.4333 - val_loss: 2.1993 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9531 - accuracy: 0.5000\n",
      "Epoch 40: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9531 - accuracy: 0.5000 - val_loss: 2.2275 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8752 - accuracy: 0.6000\n",
      "Epoch 41: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8752 - accuracy: 0.6000 - val_loss: 2.2743 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8614 - accuracy: 0.7000\n",
      "Epoch 42: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8614 - accuracy: 0.7000 - val_loss: 2.3124 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9359 - accuracy: 0.5667\n",
      "Epoch 43: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9359 - accuracy: 0.5667 - val_loss: 2.3275 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9499 - accuracy: 0.5333\n",
      "Epoch 44: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9499 - accuracy: 0.5333 - val_loss: 2.3211 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9596 - accuracy: 0.5667\n",
      "Epoch 45: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9596 - accuracy: 0.5667 - val_loss: 2.3131 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9510 - accuracy: 0.6667\n",
      "Epoch 46: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9510 - accuracy: 0.6667 - val_loss: 2.2944 - val_accuracy: 0.0714\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9288 - accuracy: 0.6000\n",
      "Epoch 47: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9288 - accuracy: 0.6000 - val_loss: 2.2840 - val_accuracy: 0.0714\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9014 - accuracy: 0.6333\n",
      "Epoch 48: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9014 - accuracy: 0.6333 - val_loss: 2.2908 - val_accuracy: 0.0714\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8433 - accuracy: 0.7333\n",
      "Epoch 49: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8433 - accuracy: 0.7333 - val_loss: 2.3069 - val_accuracy: 0.0714\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9216 - accuracy: 0.5667\n",
      "Epoch 50: val_loss did not improve from 1.41479\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9216 - accuracy: 0.5667 - val_loss: 2.3344 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3455 - accuracy: 0.3333\n",
      "Test accuracy: 33.33%\n"
     ]
    }
   ],
   "source": [
    "_, sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b1e4d0",
   "metadata": {},
   "source": [
    "## Part 3: Register the model \n",
    "Setting up MLFlow remotely to be shared requires an instance of SQL database + storage such as S3. May be too costly for this project.\n",
    "\n",
    "For our use case, we can just pickle the resulting model.\n",
    "\n",
    "After we register the model, it's ready to be consumed by an application, in our case the web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e6fec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 11:19:12.918422: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_1_09052022/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_1_09052022/assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x166c46730> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x165ed62e0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "sequence_model.save('model_1_09052022')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d407bfd4",
   "metadata": {},
   "source": [
    "## Part 4: Consume the model\n",
    "\n",
    "This phase will happen outside of this notebook, where the UI will pull our trained model, process users' video uploads, feeds it through our model, and displays the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45e41bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 11:20:18.032593: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:19.348008: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:19.485342: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:19.579244: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:19.623434: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:19.632435: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:19.677297: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:19.698617: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:19.707223: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:19.862996: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:19.872279: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:19.982645: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:20.539135: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:21.128258: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:21.137070: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:21.255046: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:21.263915: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:21.277962: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:21.286373: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:21.554119: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:21.563416: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:21.650384: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:21.659913: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:21.691942: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:21.705731: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:21.714353: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:21.813000: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-09-05 11:20:21.827064: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('model_1_09052022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8319542d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
